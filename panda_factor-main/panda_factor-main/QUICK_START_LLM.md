# ğŸš€ LLMå¤šå¯†é’¥ç³»ç»Ÿå¿«é€Ÿå¯åŠ¨

## âœ… å·²å®Œæˆé…ç½®

### 3ä¸ªAPIå¯†é’¥ + 4ä¸ªé‡‘èæ¨¡å‹

```
âœ… å¡å¯†1: sk-ljllswzyhlrrskmolcxayvemftjuzrgbiuwnedfnfjckxnpu
âœ… å¡å¯†2: sk-ridvotghvcwjqormgutcojreigmszrrqhijbezbwhbvhcedw
âœ… å¡å¯†3: sk-kefpbqtbxodjvubcvoytodjsqtmaodriwtmreialxjbonstr

âœ… DeepSeek V3 - ä»£ç åˆ†æã€å› å­ç”Ÿæˆ
âœ… Claude 4.5 - ç­–ç•¥æ¨ç†ã€é£é™©è¯„ä¼°
âœ… Kimi K2 - é•¿æ–‡æœ¬ã€è´¢æŠ¥åˆ†æ
âœ… Qwen 3 - ä¸­æ–‡ç†è§£ã€å¸‚åœºè§£è¯»
```

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

1. **è‡ªåŠ¨è½®è¯¢** - 3ä¸ªå¯†é’¥è½®æµä½¿ç”¨ï¼Œè´Ÿè½½å‡è¡¡
2. **æ•…éšœè½¬ç§»** - å•ä¸ªå¯†é’¥å¤±è´¥è‡ªåŠ¨åˆ‡æ¢
3. **æ™ºèƒ½é‡è¯•** - æ¯ä¸ªå¯†é’¥é‡è¯•3æ¬¡
4. **å¤šæ¨¡å‹** - 4ç§æ¨¡å‹é€‚é…ä¸åŒåœºæ™¯

---

## ğŸ§ª ç«‹å³æµ‹è¯•

```powershell
# æµ‹è¯•å¤šå¯†é’¥è´Ÿè½½å‡è¡¡
py test_llm_multi_key.py
```

**æµ‹è¯•å†…å®¹**:
- âœ… 3ä¸ªå¯†é’¥è½®è¯¢
- âœ… DeepSeek V3 æµ‹è¯•
- âœ… Kimi K2 æµ‹è¯•
- âœ… å¯†é’¥çŠ¶æ€ç›‘æ§

---

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ç”¨æ³•

```python
from panda_common.llm_manager import get_llm_manager

# è·å–ç®¡ç†å™¨
llm = get_llm_manager()

# è°ƒç”¨LLMï¼ˆè‡ªåŠ¨è½®è¯¢å¯†é’¥ï¼‰
response = llm.chat_completion(
    messages=[
        {"role": "user", "content": "åˆ†æè¿™ä¸ªå› å­"}
    ]
)

print(response['choices'][0]['message']['content'])
```

### æŒ‡å®šæ¨¡å‹

```python
# ä½¿ç”¨DeepSeekç”Ÿæˆå› å­ä»£ç 
response = llm.chat_completion(
    messages=[{"role": "user", "content": "å†™ä¸€ä¸ªRSIå› å­"}],
    model=llm.get_model('deepseek')
)

# ä½¿ç”¨Kimiåˆ†æé•¿æ–‡æœ¬
response = llm.chat_completion(
    messages=[{"role": "user", "content": "åˆ†æè¿™ä»½è´¢æŠ¥"}],
    model=llm.get_model('kimi'),
    max_tokens=4000
)

# ä½¿ç”¨Claudeè¿›è¡Œç­–ç•¥æ¨ç†
response = llm.chat_completion(
    messages=[{"role": "user", "content": "è®¾è®¡é‡åŒ–ç­–ç•¥"}],
    model=llm.get_model('claude')
)

# ä½¿ç”¨Qwenè§£è¯»å¸‚åœº
response = llm.chat_completion(
    messages=[{"role": "user", "content": "è§£è¯»ä»Šæ—¥è¡Œæƒ…"}],
    model=llm.get_model('qwen')
)
```

---

## ğŸ”„ å·¥ä½œåŸç†

### è½®è¯¢æœºåˆ¶

```
è¯·æ±‚1 â†’ å¡å¯†1 â†’ æˆåŠŸ âœ…
è¯·æ±‚2 â†’ å¡å¯†2 â†’ æˆåŠŸ âœ…
è¯·æ±‚3 â†’ å¡å¯†3 â†’ æˆåŠŸ âœ…
è¯·æ±‚4 â†’ å¡å¯†1 â†’ æˆåŠŸ âœ… (å¾ªç¯)
```

### æ•…éšœè½¬ç§»

```
è¯·æ±‚ â†’ å¡å¯†1 (å°è¯•1) â†’ å¤±è´¥
     â†’ å¡å¯†1 (å°è¯•2) â†’ å¤±è´¥
     â†’ å¡å¯†1 (å°è¯•3) â†’ å¤±è´¥
     â†’ åˆ‡æ¢å¡å¯†2 (å°è¯•1) â†’ æˆåŠŸ âœ…
```

---

## ğŸ“Š æ¨¡å‹é€‰æ‹©æŒ‡å—

| ä»»åŠ¡ | æ¨èæ¨¡å‹ | å‘½ä»¤ |
|------|---------|------|
| å› å­ä»£ç  | DeepSeek V3 | `llm.get_model('deepseek')` |
| è´¢æŠ¥åˆ†æ | Kimi K2 | `llm.get_model('kimi')` |
| ç­–ç•¥è®¾è®¡ | Claude 4.5 | `llm.get_model('claude')` |
| å¸‚åœºè§£è¯» | Qwen 3 | `llm.get_model('qwen')` |

---

## ğŸš€ é‡å¯æœåŠ¡

```powershell
# é‡å¯æœåŠ¡ä»¥åº”ç”¨LLMé…ç½®
py start_server_fixed.py
```

å¯åŠ¨ååº”è¯¥çœ‹åˆ°ï¼š

```
è·¯ç”±åŠ è½½çŠ¶æ€:
  âœ… å› å­API
  âœ… LLM API  â† ç°åœ¨æ”¯æŒå¤šå¯†é’¥
  âœ… Webç•Œé¢
```

---

## ğŸ“¡ APIç«¯ç‚¹

### é€šè¿‡HTTPè°ƒç”¨

```bash
curl -X POST http://127.0.0.1:8111/llm/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "åˆ†æå› å­"}
    ]
  }'
```

### è®¿é—®APIæ–‡æ¡£

```
http://127.0.0.1:8111/docs
```

æ‰¾åˆ° `panda_llm` æ ‡ç­¾æµ‹è¯•ã€‚

---

## ğŸ’° ä½™é¢æŸ¥è¯¢

è®¿é—®: https://siliconflow.ly-y.cn/

è¾“å…¥APIå¯†é’¥æŸ¥è¯¢ä½™é¢ã€‚

---

## ğŸ¯ ä¸‹ä¸€æ­¥

```powershell
# 1. æµ‹è¯•å¤šå¯†é’¥ç³»ç»Ÿ
py test_llm_multi_key.py

# 2. é‡å¯æœåŠ¡
py start_server_fixed.py

# 3. å¼€å§‹ä½¿ç”¨
# - å› å­ä»£ç ç”Ÿæˆ
# - è´¢æŠ¥åˆ†æ
# - ç­–ç•¥è®¾è®¡
# - å¸‚åœºè§£è¯»
```

---

## âœ… é…ç½®æ–‡ä»¶ä½ç½®

- **é…ç½®**: `panda_common/panda_common/config.yaml`
- **ç®¡ç†å™¨**: `panda_common/panda_common/llm_manager.py`
- **æµ‹è¯•**: `test_llm_multi_key.py`
- **æ–‡æ¡£**: `MULTI_KEY_LLM_GUIDE.md`

---

## ğŸ‰ å®Œæˆï¼

æ‚¨ç°åœ¨æ‹¥æœ‰ï¼š

âœ… **3ä¸ªAPIå¯†é’¥** - è‡ªåŠ¨è½®è¯¢ï¼Œé˜²æ­¢é¢åº¦ä¸è¶³
âœ… **4ä¸ªé‡‘èæ¨¡å‹** - é€‚é…ä¸åŒåˆ†æåœºæ™¯
âœ… **è‡ªåŠ¨æ•…éšœè½¬ç§»** - å•ä¸ªå¯†é’¥å¤±è´¥è‡ªåŠ¨åˆ‡æ¢
âœ… **æ™ºèƒ½è´Ÿè½½å‡è¡¡** - å‡è¡¡åˆ†é…è¯·æ±‚è´Ÿè½½

**å¼€å§‹ä½¿ç”¨å¼ºå¤§çš„LLMé‡‘èåˆ†æèƒ½åŠ›ï¼** ğŸš€
