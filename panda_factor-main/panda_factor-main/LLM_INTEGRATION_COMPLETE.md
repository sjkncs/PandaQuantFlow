# ğŸ‰ LLMå¤šå¯†é’¥ç³»ç»Ÿå·²é›†æˆåˆ°PandaFactor

## âœ… é›†æˆå®Œæˆ

å¤šAPIå¯†é’¥LLMç³»ç»Ÿå·²æˆåŠŸé›†æˆåˆ°PandaFactorçš„æ‰€æœ‰æ¨¡å—ï¼

---

## ğŸ”§ å·²å®Œæˆçš„é›†æˆ

### 1. æ ¸å¿ƒæœåŠ¡é›†æˆ

**æ–‡ä»¶**: `panda_llm/services/llm_service.py`

âœ… å·²é›†æˆå¤šå¯†é’¥ç®¡ç†å™¨
âœ… è‡ªåŠ¨è½®è¯¢3ä¸ªAPIå¯†é’¥
âœ… è‡ªåŠ¨æ•…éšœè½¬ç§»
âœ… æ”¯æŒ4ç§é‡‘èåˆ†ææ¨¡å‹

**å…³é”®ä¿®æ”¹**:
```python
# ä½¿ç”¨å¤šå¯†é’¥LLMç®¡ç†å™¨
self.llm_manager = get_llm_manager(config)

# è°ƒç”¨æ—¶è‡ªåŠ¨è½®è¯¢å¯†é’¥
response_dict = self.llm_manager.chat_completion(
    messages=formatted_messages,
    model=self.model,
    temperature=0.7,
    max_tokens=2000
)
```

### 2. APIç«¯ç‚¹æ‰©å±•

**æ–‡ä»¶**: `panda_llm/routes/chat_router.py`

æ–°å¢3ä¸ªAPIç«¯ç‚¹ï¼š

#### GET `/llm/status`
æŸ¥è¯¢LLMç®¡ç†å™¨çŠ¶æ€

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "total_keys": 3,
    "strategy": "round_robin",
    "default_model": "deepseek-ai/DeepSeek-V3",
    "available_models": {...},
    "key_status": [
      {
        "key": "sk-ljllswzyhlrrskmol...",
        "failures": 0,
        "last_success": "2026-01-13 14:20:30"
      }
    ]
  }
}
```

#### GET `/llm/models`
è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "models": {
      "deepseek": {
        "name": "DeepSeek V3",
        "model_id": "deepseek-ai/DeepSeek-V3",
        "description": "ä»£ç ç”Ÿæˆå’ŒæŠ€æœ¯åˆ†æä¸“å®¶",
        "best_for": ["å› å­ä»£ç ç”Ÿæˆ", "æŠ€æœ¯æŒ‡æ ‡å®ç°", "ä»£ç ä¼˜åŒ–"]
      },
      "claude": {
        "name": "Claude 4.5 Thinking",
        "model_id": "anthropic/claude-3.5-sonnet",
        "description": "æ·±åº¦æ¨ç†å’Œç­–ç•¥åˆ†æä¸“å®¶",
        "best_for": ["ç­–ç•¥è®¾è®¡", "é£é™©è¯„ä¼°", "é€»è¾‘æ¨ç†"]
      },
      "kimi": {
        "name": "Kimi K2-Thinking",
        "model_id": "Pro/moonshotai/Kimi-K2-Thinking",
        "description": "é•¿æ–‡æœ¬å¤„ç†ä¸“å®¶",
        "best_for": ["è´¢æŠ¥åˆ†æ", "ç ”æŠ¥è§£è¯»", "é•¿æ–‡æ¡£ç†è§£"]
      },
      "qwen": {
        "name": "Qwen 3",
        "model_id": "Qwen/Qwen2.5-72B-Instruct",
        "description": "ä¸­æ–‡ç†è§£ä¸“å®¶",
        "best_for": ["å¸‚åœºè§£è¯»", "æ–°é—»åˆ†æ", "ä¸­æ–‡å¯¹è¯"]
      }
    },
    "default_model": "deepseek-ai/DeepSeek-V3",
    "total_api_keys": 3,
    "load_balance_strategy": "round_robin"
  }
}
```

#### POST `/llm/switch_model`
åˆ‡æ¢LLMæ¨¡å‹

**è¯·æ±‚ç¤ºä¾‹**:
```json
{
  "model_type": "kimi"
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "success": true,
  "data": {
    "model_type": "kimi",
    "model_id": "Pro/moonshotai/Kimi-K2-Thinking",
    "message": "å·²åˆ‡æ¢åˆ° kimi æ¨¡å‹"
  }
}
```

---

## ğŸŒ Webç•Œé¢è®¿é—®

### 1. APIæ–‡æ¡£

è®¿é—®: http://127.0.0.1:8111/docs

åœ¨APIæ–‡æ¡£ä¸­å¯ä»¥æ‰¾åˆ°ï¼š
- âœ… `/llm/status` - æŸ¥çœ‹å¤šå¯†é’¥çŠ¶æ€
- âœ… `/llm/models` - æŸ¥çœ‹å¯ç”¨æ¨¡å‹
- âœ… `/llm/switch_model` - åˆ‡æ¢æ¨¡å‹
- âœ… `/chat` - èŠå¤©æ¥å£ï¼ˆå·²æ”¯æŒå¤šå¯†é’¥ï¼‰

### 2. å› å­ç•Œé¢

è®¿é—®: http://127.0.0.1:8111/factor/

åœ¨å› å­ç•Œé¢ä¸­ï¼š
- âœ… LLMèŠå¤©åŠŸèƒ½è‡ªåŠ¨ä½¿ç”¨å¤šå¯†é’¥
- âœ… å•ä¸ªå¯†é’¥å¤±è´¥è‡ªåŠ¨åˆ‡æ¢
- âœ… æ”¯æŒ4ç§æ¨¡å‹é€‰æ‹©

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### æ–¹å¼1: é€šè¿‡Webç•Œé¢

1. è®¿é—®å› å­ç•Œé¢: http://127.0.0.1:8111/factor/
2. ä½¿ç”¨LLMèŠå¤©åŠŸèƒ½
3. ç³»ç»Ÿè‡ªåŠ¨è½®è¯¢3ä¸ªAPIå¯†é’¥
4. å•ä¸ªå¯†é’¥å¤±è´¥è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª

### æ–¹å¼2: é€šè¿‡APIè°ƒç”¨

#### æŸ¥è¯¢LLMçŠ¶æ€

```bash
curl http://127.0.0.1:8111/llm/status
```

#### è·å–å¯ç”¨æ¨¡å‹

```bash
curl http://127.0.0.1:8111/llm/models
```

#### åˆ‡æ¢æ¨¡å‹

```bash
curl -X POST http://127.0.0.1:8111/llm/switch_model \
  -H "Content-Type: application/json" \
  -d '{"model_type": "kimi"}'
```

#### èŠå¤©ï¼ˆè‡ªåŠ¨ä½¿ç”¨å¤šå¯†é’¥ï¼‰

```bash
curl -X POST http://127.0.0.1:8111/chat \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "test_user",
    "message": "å¸®æˆ‘åˆ†æè¿™ä¸ªå› å­",
    "session_id": null
  }'
```

### æ–¹å¼3: åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from panda_common.llm_manager import get_llm_manager

# è·å–ç®¡ç†å™¨
llm = get_llm_manager()

# è‡ªåŠ¨è½®è¯¢å¯†é’¥è°ƒç”¨
response = llm.chat_completion(
    messages=[
        {"role": "user", "content": "åˆ†æå› å­"}
    ]
)

# ä½¿ç”¨æŒ‡å®šæ¨¡å‹
response = llm.chat_completion(
    messages=[
        {"role": "user", "content": "ç”ŸæˆRSIå› å­ä»£ç "}
    ],
    model=llm.get_model('deepseek')  # ä½¿ç”¨DeepSeek
)

# æŸ¥çœ‹çŠ¶æ€
status = llm.get_status()
print(f"å¯ç”¨å¯†é’¥: {status['total_keys']}")
print(f"è´Ÿè½½ç­–ç•¥: {status['strategy']}")
```

---

## ğŸ“Š åŠŸèƒ½å¯¹æ¯”

| åŠŸèƒ½ | é›†æˆå‰ | é›†æˆå |
|------|--------|--------|
| APIå¯†é’¥ | å•ä¸ª | 3ä¸ªå¹¶è” |
| æ•…éšœè½¬ç§» | âŒ | âœ… è‡ªåŠ¨åˆ‡æ¢ |
| è´Ÿè½½å‡è¡¡ | âŒ | âœ… è½®è¯¢ç­–ç•¥ |
| æ¨¡å‹é€‰æ‹© | å›ºå®š | 4ç§å¯é€‰ |
| çŠ¶æ€ç›‘æ§ | âŒ | âœ… å®æ—¶æŸ¥è¯¢ |
| å®¹é”™èƒ½åŠ› | ä½ | é«˜ï¼ˆ3å±‚ä¿æŠ¤ï¼‰ |

---

## ğŸ¯ åº”ç”¨åœºæ™¯

### åœºæ™¯1: å› å­ä»£ç ç”Ÿæˆ

**æ¨èæ¨¡å‹**: DeepSeek V3

```python
# åœ¨å› å­ç•Œé¢èŠå¤©æ¡†è¾“å…¥
"å¸®æˆ‘å†™ä¸€ä¸ª20æ—¥ç§»åŠ¨å¹³å‡çº¿å› å­"

# ç³»ç»Ÿè‡ªåŠ¨ï¼š
# 1. ä½¿ç”¨DeepSeek V3æ¨¡å‹
# 2. è½®è¯¢ä½¿ç”¨3ä¸ªAPIå¯†é’¥
# 3. ç”Ÿæˆé«˜è´¨é‡å› å­ä»£ç 
```

### åœºæ™¯2: è´¢æŠ¥åˆ†æ

**æ¨èæ¨¡å‹**: Kimi K2-Thinking

```python
# åˆ‡æ¢åˆ°Kimiæ¨¡å‹
POST /llm/switch_model {"model_type": "kimi"}

# è¾“å…¥é•¿æ–‡æœ¬è´¢æŠ¥
"åˆ†æä»¥ä¸‹è´¢æŠ¥å†…å®¹..."

# ç³»ç»Ÿè‡ªåŠ¨ï¼š
# 1. ä½¿ç”¨Kimié•¿æ–‡æœ¬èƒ½åŠ›
# 2. å¤šå¯†é’¥è½®è¯¢
# 3. æ·±åº¦åˆ†æè´¢æŠ¥
```

### åœºæ™¯3: ç­–ç•¥è®¾è®¡

**æ¨èæ¨¡å‹**: Claude 4.5

```python
# åˆ‡æ¢åˆ°Claudeæ¨¡å‹
POST /llm/switch_model {"model_type": "claude"}

# è¾“å…¥ç­–ç•¥éœ€æ±‚
"åŸºäºè¿™äº›å› å­è®¾è®¡é‡åŒ–ç­–ç•¥"

# ç³»ç»Ÿè‡ªåŠ¨ï¼š
# 1. ä½¿ç”¨Claudeæ¨ç†èƒ½åŠ›
# 2. å¤šå¯†é’¥ä¿éšœ
# 3. ç”Ÿæˆä¸¥å¯†ç­–ç•¥
```

### åœºæ™¯4: å¸‚åœºè§£è¯»

**æ¨èæ¨¡å‹**: Qwen 3

```python
# åˆ‡æ¢åˆ°Qwenæ¨¡å‹
POST /llm/switch_model {"model_type": "qwen"}

# è¾“å…¥å¸‚åœºä¿¡æ¯
"è§£è¯»ä»Šå¤©çš„å¸‚åœºè¡Œæƒ…"

# ç³»ç»Ÿè‡ªåŠ¨ï¼š
# 1. ä½¿ç”¨Qwenä¸­æ–‡ç†è§£
# 2. å¤šå¯†é’¥æ”¯æŒ
# 3. å‡†ç¡®å¸‚åœºè§£è¯»
```

---

## ğŸ”„ å·¥ä½œæµç¨‹

### ç”¨æˆ·è¯·æ±‚æµç¨‹

```
ç”¨æˆ·è¾“å…¥
  â†“
Webç•Œé¢/API
  â†“
LLMService
  â†“
LLMç®¡ç†å™¨
  â†“
é€‰æ‹©APIå¯†é’¥ï¼ˆè½®è¯¢ï¼‰
  â†“
è°ƒç”¨ç¡…åŸºæµåŠ¨API
  â†“
æˆåŠŸ â†’ è¿”å›ç»“æœ
å¤±è´¥ â†’ åˆ‡æ¢ä¸‹ä¸€ä¸ªå¯†é’¥ â†’ é‡è¯•
```

### å¯†é’¥è½®è¯¢ç¤ºä¾‹

```
è¯·æ±‚1 â†’ å¡å¯†1 â†’ æˆåŠŸ âœ…
è¯·æ±‚2 â†’ å¡å¯†2 â†’ æˆåŠŸ âœ…
è¯·æ±‚3 â†’ å¡å¯†3 â†’ æˆåŠŸ âœ…
è¯·æ±‚4 â†’ å¡å¯†1 â†’ æˆåŠŸ âœ… (å¾ªç¯)
```

### æ•…éšœè½¬ç§»ç¤ºä¾‹

```
è¯·æ±‚ â†’ å¡å¯†1 (å°è¯•1) â†’ å¤±è´¥
     â†’ å¡å¯†1 (å°è¯•2) â†’ å¤±è´¥
     â†’ å¡å¯†1 (å°è¯•3) â†’ å¤±è´¥
     â†’ åˆ‡æ¢å¡å¯†2 (å°è¯•1) â†’ æˆåŠŸ âœ…
```

---

## ğŸ“ é…ç½®è¯´æ˜

### å½“å‰é…ç½®

**æ–‡ä»¶**: `panda_common/config.yaml`

```yaml
# 3ä¸ªAPIå¯†é’¥å¹¶è”
LLM_API_KEYS:
  - "sk-ljllswzyhlrrskmolcxayvemftjuzrgbiuwnedfnfjckxnpu"
  - "sk-ridvotghvcwjqormgutcojreigmszrrqhijbezbwhbvhcedw"
  - "sk-kefpbqtbxodjvubcvoytodjsqtmaodriwtmreialxjbonstr"

# 4ç§é‡‘èåˆ†ææ¨¡å‹
LLM_MODELS:
  deepseek: "deepseek-ai/DeepSeek-V3"
  claude: "anthropic/claude-3.5-sonnet"
  kimi: "Pro/moonshotai/Kimi-K2-Thinking"
  qwen: "Qwen/Qwen2.5-72B-Instruct"

# è´Ÿè½½å‡è¡¡ç­–ç•¥
LLM_LOAD_BALANCE_STRATEGY: "round_robin"
LLM_MAX_RETRIES: 3
LLM_RETRY_DELAY: 1
```

---

## ğŸ§ª æµ‹è¯•é›†æˆ

### æµ‹è¯•1: å¤šå¯†é’¥ç³»ç»Ÿ

```powershell
py test_llm_multi_key.py
```

### æµ‹è¯•2: APIç«¯ç‚¹

```bash
# æµ‹è¯•çŠ¶æ€æŸ¥è¯¢
curl http://127.0.0.1:8111/llm/status

# æµ‹è¯•æ¨¡å‹åˆ—è¡¨
curl http://127.0.0.1:8111/llm/models

# æµ‹è¯•æ¨¡å‹åˆ‡æ¢
curl -X POST http://127.0.0.1:8111/llm/switch_model \
  -H "Content-Type: application/json" \
  -d '{"model_type": "deepseek"}'
```

### æµ‹è¯•3: Webç•Œé¢

1. è®¿é—®: http://127.0.0.1:8111/factor/
2. æ‰“å¼€LLMèŠå¤©
3. è¾“å…¥æµ‹è¯•æ¶ˆæ¯
4. è§‚å¯Ÿå¤šå¯†é’¥è½®è¯¢å·¥ä½œ

---

## âœ… é›†æˆæ£€æŸ¥æ¸…å•

- [x] é›†æˆLLMç®¡ç†å™¨åˆ°LLMService
- [x] ä¿®æ”¹chat_completionä½¿ç”¨å¤šå¯†é’¥
- [x] æ·»åŠ /llm/statusç«¯ç‚¹
- [x] æ·»åŠ /llm/modelsç«¯ç‚¹
- [x] æ·»åŠ /llm/switch_modelç«¯ç‚¹
- [x] é…ç½®3ä¸ªAPIå¯†é’¥
- [x] é…ç½®4ç§æ¨¡å‹
- [x] è®¾ç½®è´Ÿè½½å‡è¡¡ç­–ç•¥
- [ ] é‡å¯æœåŠ¡åº”ç”¨æ›´æ”¹
- [ ] æµ‹è¯•Webç•Œé¢LLMåŠŸèƒ½
- [ ] æµ‹è¯•APIç«¯ç‚¹
- [ ] éªŒè¯å¤šå¯†é’¥è½®è¯¢

---

## ğŸš€ é‡å¯æœåŠ¡

```powershell
# åœæ­¢å½“å‰æœåŠ¡ï¼ˆCtrl+Cï¼‰
# é‡æ–°å¯åŠ¨
py start_server_fixed.py
```

å¯åŠ¨ååº”è¯¥çœ‹åˆ°ï¼š

```
è·¯ç”±åŠ è½½çŠ¶æ€:
  âœ… å› å­API
  âœ… LLM API  â† ç°åœ¨æ”¯æŒå¤šå¯†é’¥å’Œ4ç§æ¨¡å‹
  âœ… Webç•Œé¢
```

---

## ğŸ‰ é›†æˆå®Œæˆï¼

ç°åœ¨PandaFactorçš„æ‰€æœ‰LLMåŠŸèƒ½éƒ½å·²æ”¯æŒï¼š

âœ… **3ä¸ªAPIå¯†é’¥å¹¶è”** - é˜²æ­¢å•ç‚¹æ•…éšœ
âœ… **4ç§é‡‘èæ¨¡å‹** - é€‚é…ä¸åŒåœºæ™¯
âœ… **è‡ªåŠ¨è½®è¯¢** - è´Ÿè½½å‡è¡¡
âœ… **æ•…éšœè½¬ç§»** - é«˜å¯ç”¨æ€§
âœ… **Webç•Œé¢é›†æˆ** - æ— ç¼ä½¿ç”¨
âœ… **APIç«¯ç‚¹æ‰©å±•** - çµæ´»è°ƒç”¨

**ç«‹å³ä½“éªŒ**:
1. é‡å¯æœåŠ¡: `py start_server_fixed.py`
2. è®¿é—®å› å­ç•Œé¢: http://127.0.0.1:8111/factor/
3. ä½¿ç”¨LLMèŠå¤©åŠŸèƒ½
4. äº«å—å¤šå¯†é’¥é«˜å¯ç”¨LLMæœåŠ¡ï¼

ğŸš€ **PandaFactor + å¤šå¯†é’¥LLM = å¼ºå¤§çš„é‡‘èåˆ†æå¹³å°ï¼**
