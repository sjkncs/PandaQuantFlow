"""
æµ‹è¯•LLMèŠå¤©åŠŸèƒ½
"""

import sys
import os

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, "panda_common"))

print("=" * 70)
print("æµ‹è¯•LLMèŠå¤©åŠŸèƒ½")
print("=" * 70)
print()

try:
    from panda_common.config import config
    
    print("[1/3] è¯»å–é…ç½®...")
    llm_api_key = config.get('LLM_API_KEY', '')
    llm_model = config.get('LLM_MODEL', '')
    llm_base_url = config.get('LLM_BASE_URL', '')
    
    print(f"  API Key: {llm_api_key[:20]}...")
    print(f"  æ¨¡å‹: {llm_model}")
    print(f"  Base URL: {llm_base_url}")
    print()
    
    print("[2/3] æµ‹è¯•APIè¿æ¥...")
    
    import requests
    
    # æµ‹è¯•èŠå¤©è¡¥å…¨
    headers = {
        "Authorization": f"Bearer {llm_api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": llm_model,
        "messages": [
            {
                "role": "user",
                "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
            }
        ],
        "max_tokens": 100,
        "temperature": 0.7
    }
    
    print(f"  å‘é€è¯·æ±‚åˆ°: {llm_base_url}/chat/completions")
    print(f"  ä½¿ç”¨æ¨¡å‹: {llm_model}")
    print()
    
    response = requests.post(
        f"{llm_base_url}/chat/completions",
        headers=headers,
        json=data,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        print("âœ… APIè¿æ¥æˆåŠŸï¼")
        print()
        print("[3/3] å“åº”å†…å®¹:")
        print("-" * 70)
        
        if 'choices' in result and len(result['choices']) > 0:
            message = result['choices'][0]['message']['content']
            print(message)
            print("-" * 70)
            print()
            
            # æ˜¾ç¤ºä½¿ç”¨æƒ…å†µ
            if 'usage' in result:
                usage = result['usage']
                print("Tokenä½¿ç”¨æƒ…å†µ:")
                print(f"  è¾“å…¥: {usage.get('prompt_tokens', 0)} tokens")
                print(f"  è¾“å‡º: {usage.get('completion_tokens', 0)} tokens")
                print(f"  æ€»è®¡: {usage.get('total_tokens', 0)} tokens")
        else:
            print("å“åº”æ ¼å¼å¼‚å¸¸:")
            print(result)
    else:
        print(f"âŒ APIè¯·æ±‚å¤±è´¥")
        print(f"  çŠ¶æ€ç : {response.status_code}")
        print(f"  å“åº”: {response.text}")
    
    print()
    print("=" * 70)
    print("ğŸ‰ LLMåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print()
    print("å¯ç”¨çš„æ¨¡å‹:")
    print("  1. Pro/moonshotai/Kimi-K2-Thinking (å½“å‰)")
    print("  2. claude-4.5-thinking")
    print("  3. Qwen/Qwen2.5-72B-Instruct")
    print("  4. deepseek-ai/DeepSeek-V3")
    print()
    print("åˆ‡æ¢æ¨¡å‹: ä¿®æ”¹ config.yaml ä¸­çš„ LLM_MODEL")
    print("=" * 70)
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print()
    print("è¯·å®‰è£…ä¾èµ–:")
    print("  pip install requests")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
